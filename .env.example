POSTGRES_USER=pineapple
POSTGRES_PASSWORD=pineapple
POSTGRES_DB=pineapple
POSTGRES_HOST=db
POSTGRES_PORT=5432
DATABASE_URL=postgresql+psycopg2://pineapple:pineapple@db:5432/pineapple
REDIS_URL=redis://redis:6379/0

# API key for protected endpoints (e.g., /subreddits/{name}/refresh)
# Generate a new one with: python -c "import secrets; print(secrets.token_urlsafe(32))"
API_KEY=your-api-key-here

# Timezone for all containers
TZ=Europe/Copenhagen

# Log level for scanner (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Delay in seconds between API requests to avoid rate limiting
API_RATE_DELAY_SECONDS=7
API_MAX_CALLS_MINUTE=8

# Hours to spend refreshing metadata after each scan completes (before next scan)
METADATA_REFRESH_HOURS=2

# Start with metadata refresh on scanner startup (true/false)
# If true: scanner refreshes metadata first, then scans for new mentions
# If false: scanner starts immediately with scanning for new mentions
SCAN_FOR_METADATA_FIRST=false

# Testing helper variables (to limit scope during tests)
# Maximum number of posts to process per source subreddit (e.g., 2 posts from nsfw411 AND 2 from wowthissubexists)
TEST_MAX_POSTS_PER_SUBREDDIT=

# How many days back to rescan existing posts for new/edited comments.
POST_COMMENT_LOOKBACK_DAYS=180

# NOTE: Scan configuration is now managed in the database via these tables:
# - subreddit_scan_configs: which subreddits to scan and how (users, NSFW filter)
# - ignored_subreddits: subreddits to never record mentions for
# - ignored_users: users whose mentions should not be recorded
# Use the database to manage scan targets instead of .env variables.

# Runtime/config values
SUBABOUT_MAX_RETRIES=3
HTTP_REQUEST_TIMEOUT=15

# Set to true, to add initial scan configuration on container start to the database.
# This is idempotent and safe to run multiple times.
INIT_SCAN_CONFIG=true
